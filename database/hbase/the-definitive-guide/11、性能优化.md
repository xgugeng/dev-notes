<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [11.1 垃圾回收](#111-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6)
- [11.2 本地 memstore 分配缓冲区](#112-%E6%9C%AC%E5%9C%B0-memstore-%E5%88%86%E9%85%8D%E7%BC%93%E5%86%B2%E5%8C%BA)
- [11.3 压缩](#113-%E5%8E%8B%E7%BC%A9)
  - [11.3.1 可用的编解码器](#1131-%E5%8F%AF%E7%94%A8%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8)
- [11.4 优化拆分和合并](#114-%E4%BC%98%E5%8C%96%E6%8B%86%E5%88%86%E5%92%8C%E5%90%88%E5%B9%B6)
  - [11.4.1 管理拆分](#1141-%E7%AE%A1%E7%90%86%E6%8B%86%E5%88%86)
  - [11.4.2 region 热点](#1142-region-%E7%83%AD%E7%82%B9)
  - [11.4.3 预拆分 region](#1143-%E9%A2%84%E6%8B%86%E5%88%86-region)
- [11.5 均衡负载](#115-%E5%9D%87%E8%A1%A1%E8%B4%9F%E8%BD%BD)
- [11.6 合并 region](#116-%E5%90%88%E5%B9%B6-region)
- [11.7 客户端 API：最佳实践](#117-%E5%AE%A2%E6%88%B7%E7%AB%AF-api%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5)
- [11.8 配置](#118-%E9%85%8D%E7%BD%AE)
  - [减少 ZooKeeper 超时的发生](#%E5%87%8F%E5%B0%91-zookeeper-%E8%B6%85%E6%97%B6%E7%9A%84%E5%8F%91%E7%94%9F)
  - [增加处理线程](#%E5%A2%9E%E5%8A%A0%E5%A4%84%E7%90%86%E7%BA%BF%E7%A8%8B)
  - [增加堆大小](#%E5%A2%9E%E5%8A%A0%E5%A0%86%E5%A4%A7%E5%B0%8F)
  - [启用数据压缩](#%E5%90%AF%E7%94%A8%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9)
  - [增加 region 大小](#%E5%A2%9E%E5%8A%A0-region-%E5%A4%A7%E5%B0%8F)
  - [调整块缓存大小](#%E8%B0%83%E6%95%B4%E5%9D%97%E7%BC%93%E5%AD%98%E5%A4%A7%E5%B0%8F)
  - [调整 memstore 限制](#%E8%B0%83%E6%95%B4-memstore-%E9%99%90%E5%88%B6)
  - [增加阻塞时存储文件数目](#%E5%A2%9E%E5%8A%A0%E9%98%BB%E5%A1%9E%E6%97%B6%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6%E6%95%B0%E7%9B%AE)
  - [增加阻塞倍率](#%E5%A2%9E%E5%8A%A0%E9%98%BB%E5%A1%9E%E5%80%8D%E7%8E%87)
  - [减少最大日志文件限制](#%E5%87%8F%E5%B0%91%E6%9C%80%E5%A4%A7%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E9%99%90%E5%88%B6)
- [11.9 负载测试](#119-%E8%B4%9F%E8%BD%BD%E6%B5%8B%E8%AF%95)
- [导航](#%E5%AF%BC%E8%88%AA)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 11.1 垃圾回收

垃圾回收时 master 通常不会产生问题，因为 master 没有处理过重的负载。

memstore 写入磁盘的数据是客户端在不同时间写入的，它占据的堆空间可能是不连续的，JVM 的堆内存就会出现空洞。

数据会根据在内存中停留的时间被保存在 Java 堆中分代结构的不同位置：被快速插入且被刷写到磁盘中的数据，被分配到年轻代（young generation）或新生代（new generation）的堆中。这种空间可以被迅速回收，对内存管理没有影响。

如果数据再内存中停留时间过长，对应的数据就提升为老生代（old generation）或终生代（tenured generation）。年轻代和老生代的不同点在于空间代销：年轻代占用的空间在128M ~ 512M。老生代机会占据了所有的堆内存。

指定新生代的空间：

```
-XX:MaxNewSize=128m -XX:NewSize=128m
// 等同于
-Xmn128m
```

强烈建议在 JRE 日志中输出垃圾回收的详情，用户可以添加一下的 JRE 选项：

```
-verboseL:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XLoggc:hbase.log
```

用户也可以指定 GC 策略，推荐的是：

```
-XX:+UseParNewGC 和 -XX:+UseConcMarkSweepGC
```

UseParNewGC 将停止运行 Java 进程而去清空年轻代堆。这个花费很短时间。这个策略对较小的年轻代可以接受，但不适合老生代。在最差的情况，以上回收策略会造成树苗的停顿。

UseConcMarkSweepGC 是并行标记回收器，它在工作时不停止运行 Java 进程，尽可能异步完成操作。CMS 还有一个额外的开关选项，控制什么时候触发标记清理：

```
-XX:CMSInitiatingOccupancyFraction=70
```



# 11.2 本地 memstore 分配缓冲区

HBase 0.90引入了一种高级机制来缓解 region server 内存碎片的问题，这个问题是由于不断创建和释放内存空间造成的：本地 memstore 分配缓冲区（Memstore-Local Allocation Buffers，MSLAB）。

MSLAB 只允许从对中分配相同大小的对象，一旦这些对象分配并且最终被回收，它们将在堆中留下固定大小的空洞。之后调用相同大小的新对象会重新使用这些空洞。

MSLAB 的代价是可能会更加浪费堆空间，因为用户不可能把缓冲区都用到最后一个字节。



# 11.3 压缩

HBase支持列族以上级别的数据压缩。推荐开启压缩，CPU 压缩和解压消耗的会见比从磁盘中读取和写入消耗的时间更短。

## 11.3.1 可用的编解码器

HBase 没有提供嵌入式的压缩算法，用户需要提前编译构建。

| 算法           | 压缩 % | 压缩 MB/s | 解压 MB/s |
| ------------ | ---- | ------- | ------- |
| GZIP         | 13.4 | 21      | 118     |
| LZO          | 20.5 | 135     | 410     |
| Zippy/Snappy | 22.2 | 175     | 409     |

GZIP 在压缩上有优势，但也是 CPU 密集型算法，不推荐。

Snappy 有和 LZO 一样的质量，并有兼容的许可使用。推荐 Snappy。



# 11.4 优化拆分和合并

## 11.4.1 管理拆分

HBase 是自动处理 region 拆分的：一旦它们达到既定的阈值，region 就会被拆分为两个。

用户可以使用`split`和`major_compact`来手动拆分，最好在不同的 region 上交错进行，可以避免拆分/合并风暴。

## 11.4.2 region 热点

用户最好采用盐析主键（salt-key）或使用随机的行键来负载均衡。

缓解region 热点的途径就是手动拆分 region。

## 11.4.3 预拆分 region

`createTable`的时候，输入`SPLITS`参数。



# 11.5 均衡负载

master 有一个内置的均衡器，默认情况下五分钟运行一次。它会尝试均匀分配 region 到所有 region server。启动均衡器时，它会先确定一个 region 分配计划，该计划用于描述 region 如何移动，然后通过迭代调用管理 API 中的 `unassign()`方法开始移动 region。

均衡器有一个可以限制自身运行时间的上限。



# 11.6 合并 region

```shell
hbase org.apache.hadoop.hbase.util.Merge
```



# 11.7 客户端 API：最佳实践

- 禁止自动刷写

  有大量写入时，使用 `setAutoFlush(false)`，确认`HTable`关闭自动刷写。否则每个`Put`实例都会被逐个送到 region server。使用缓冲列表，直到其满了之后再送出所有的`Put`请求。显式刷写使用`flushCommits()`。


- 使用扫描缓存

  使用默认的值意味着每条数据都要请求 region server。这里要权衡传输数据的开销和内存的开销。

- 限定扫描范围

  `Scan.addFamily`限定返回客户端的列。

- 关闭`ResultScanner`

  这不会带来性能提升，但会避免可能的性能问题。如果忘记关闭`ResultScanner`，可能对服务端造成影响。

- 块缓存用法

  `Scan`可使用`setCacheBlocks()`方法来使用 region server 中的块缓存。对于那些频发访问的行，建议使用块缓存。

- 优化获取行键的方式

  当执行一个表的扫描以获取行键（没有列、时间戳），使用带有`MUST_PASS_ALL`操作符的`FilterList`。组合过滤器会把发现的第一个 KeyValue 行键返回，减少网络传输。

- 关闭 `Put` 上的 WAL

  这样服务器端不会把这个`Put`写到 WAL 中，而只存在 memstore 中。这带来的性能提升并不明显，反而会丢失数据。



# 11.8 配置

## 减少 ZooKeeper 超时的发生

默认在 region server 和 ZooKeeper 集群的超时时间是3分钟。如果设置为1分钟，master 就能很快发现这一故障。

改变值之前，确认用户服务器上 JVM 的垃圾回收机制是可控的。因为长时间 GC 时间超过 ZooKeeper 会话的超时上限会导致误判 region server 为崩溃。

## 增加处理线程

`hbase.regionserver.handler.count`定义了响应外部用户访问数据表请求的线程数。默认为10偏小，这是为了防止用户在客户端高并发使用交大些缓冲区的情况下使服务器过载。设得小时优化单次请求设计的数据量达到 MB 级。当单次请求开销较小，可以将线程数调高。

设置过高会导致 OOM。

## 增加堆大小

可以给 HBase 分配 8GB 以上的空间。

## 启用数据压缩

推荐 Snappy。

## 增加 region 大小

更大的 region 可以减少集群总的 region 数量。一般来说，较少的 region 可以让集群运行更平稳。一个 region 变热点后，再手动拆分。

## 调整块缓存大小

控制堆汇总块缓存大小的属性是百分比。如果块缓存被频繁换入换出，考虑增加块缓存大小。

用户负责多数为读请求是另一个增加块缓存的原因，可以帮助用户缓存更多的数据。

## 调整 memstore 限制

当用户主要在处理读请求时，考虑同时减少 memstore 的上下限来增加块缓存的空间。

如果主要是写请求，且数据量都很小，如5MB，则考虑增加内存存储的限制来降低过度 I/O。

## 增加阻塞时存储文件数目

`hbase.hstore.blockingStoreFiles`这个值决定了当存储文件的数目达到阈值时，更新操作会被阻塞，并以此来给合并操作留出时间来减少存储文件的数目。

## 增加阻塞倍率

`hbase.hregion.memstore.block.multiplier`用于阻塞来自客户端数据请求的安全闩值。当 memstore 达到`multipilier * flush`的大小限制时会阻止进一步的跟新。

当有足够的存储空间时，可以增加这个值来更加平滑处理写入突发流量。

## 减少最大日志文件限制

设置`hbase.regionserver.maxlogs`属性使得用户能够控制基于磁盘的 WAL 文件数目，进而控制刷写频率。

降低这个值会强迫服务器更频繁地将数据刷写到磁盘上。



# 11.9 负载测试

```shell
hbase org.apache.hadoop.hbase.PerformanceEvaluation
```

或者试一下 YCSB（Yahoo！Cloud Serving Benchmark）。


# 导航

[目录](README.md)

上一章：[10、集群监控](10、集群监控.md)

下一章：[12、集群管理](12、集群管理.md)
