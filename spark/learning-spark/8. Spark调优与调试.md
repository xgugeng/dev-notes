<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [8.1 使用`SparkConf`配置Spark](#81-%E4%BD%BF%E7%94%A8sparkconf%E9%85%8D%E7%BD%AEspark)
- [8.2 Spark执行的组成部分：作业、任务和步骤](#82-spark%E6%89%A7%E8%A1%8C%E7%9A%84%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86%E4%BD%9C%E4%B8%9A%E4%BB%BB%E5%8A%A1%E5%92%8C%E6%AD%A5%E9%AA%A4)
- [8.3 查找信息](#83-%E6%9F%A5%E6%89%BE%E4%BF%A1%E6%81%AF)
  - [8.3.1 Spark网页用户界面](#831-spark%E7%BD%91%E9%A1%B5%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2)
  - [8.3.2 驱动器进程和执行器进程的日志](#832-%E9%A9%B1%E5%8A%A8%E5%99%A8%E8%BF%9B%E7%A8%8B%E5%92%8C%E6%89%A7%E8%A1%8C%E5%99%A8%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%97%A5%E5%BF%97)
- [8.4 关键性能考量](#84-%E5%85%B3%E9%94%AE%E6%80%A7%E8%83%BD%E8%80%83%E9%87%8F)
  - [8.4.1 并行度](#841-%E5%B9%B6%E8%A1%8C%E5%BA%A6)
  - [8.4.2 序列化格式](#842-%E5%BA%8F%E5%88%97%E5%8C%96%E6%A0%BC%E5%BC%8F)
  - [8.4.3 内存管理](#843-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86)
  - [8.4.4 硬件供给](#844-%E7%A1%AC%E4%BB%B6%E4%BE%9B%E7%BB%99)
- [导航](#%E5%AF%BC%E8%88%AA)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 8.1 使用`SparkConf`配置Spark

创建出一个 `SparkContext` 时，就需要创建出一个 `SparkConf` 实例。

```scala 
// 创建一个conf对象
val conf = new SparkConf()
conf.set("spark.app.name", "My Spark App")
conf.set("spark.master", "local[4]")
conf.set("spark.ui.port", "36000") // 重载默认端口配置

// 使用这个配置对象创建一个SparkContext
val sc = new SparkContext(conf)
```

`SparkConf` 实例包含用户要重载的配置选项的键值对。Spark 中的每个配置选项都是基于字符串形式的键值对。

除了在代码中设置，Spark 允许通过 `spark-submit` 工具动态设置配置项。当应用被 `spark-submit` 脚本启动时，脚本会把这些配置项设置到运行环境中。当一个新的 `SparkConf` 被创建出来时，这些环境变量会被检测出来并且自动配好。这样，在使用 `spark-submit` 时，用户应用中只要创建一个“空”的 `SparkConf` ，并直接传给 `SparkContext` 的构造方法就行了。

```shell
$ bin/spark-submit \
  --class com.example.MyApp \
  --master local[4] \
  --name "My Spark App" \
  --conf spark.ui.port=36000 \
  myApp.jar
```

`spark-submit` 也支持从文件中读取配置项的值。这对于设置一些与环境相关的配置项比较有用，方便不同用户共享这些配置（比如默认的 Spark 主节点）。默认情况下，`spark-submit` 脚本会在 Spark 安装目录中找到 `conf/spark-defaults.conf` 文件，尝试读取该文件中以空格隔开的键值对数据。你也可以通过 `spark-submit` 的 `--properties-File` 标记，自定义该文件的路径。

```
$ bin/spark-submit \
  --class com.example.MyApp \
  --properties-file my-config.conf \
  myApp.jar

## Contents of my-config.conf ##
spark.master    local[4]
spark.app.name  "My Spark App"
spark.ui.port   36000
```

Spark 有特定的优先级顺序来选择实际配置。优先级最高的是在用户代码中显式调用 `set()` 方法设置的选项。其次是通过 `spark-submit` 传递的参数，再次是写在配置文件中的值，最后是系统的默认值。



# 8.2 Spark执行的组成部分：作业、任务和步骤

Spark 执行时有下面所列的这些流程:

1. 用户代码定义RDD的有向无环图

   RDD 上的操作会创建出新的 RDD，并引用它们的父节点，这样就创建出了一个图。

2. 行动操作把有向无环图强制转译为执行计划

   当你调用 RDD 的一个行动操作时，这个 RDD 就必须被计算出来。这也要求计算出该 RDD 的父节点。Spark 调度器提交一个作业 来计算所有必要的 RDD。这个作业会包含一个或多个步骤 ，每个步骤其实也就是一波并行执行的计算任务 。一个步骤对应有向无环图中的一个或多个 RDD，一个步骤对应多个 RDD 是因为发生了流水线执行 。

3. 任务于集群中调度并执行

   步骤是按顺序处理的，任务则独立地启动来计算出RDD的一部分。一旦作业的最后一个步骤结束，一个行动操作也就执行完毕了。




# 8.3 查找信息

Spark 在应用执行时记录详细的进度信息和性能指标可以在两个地方找到：

1. Spark的网页界面
2. 驱动器和执行器进程的日志文件

## 8.3.1 Spark网页用户界面

默认情况下，它在驱动器程序所在机器的 4040 端口上。对于 YARN 集群模式来说，应用的驱动器程序会运行在集群内部，你应该通过 YARN 的资源管理器来访问用户界面。YARN 的资源管理器会把请求直接转发给驱动器程序。

用户界面由4个不同页面组成：

1. 作业界面。步骤与任务的进度和指标，以及更多内容
2. 存储界面。已缓存的RDD的信息
3. 执行器界面。应用中的执行器进程列表
4. 环境界面。调试Spark配置项

## 8.3.2 驱动器进程和执行器进程的日志

Spark 日志文件的具体位置取决于部署模式：

- 在 Spark 独立模式下，所有日志会在独立模式*主节点*的网页用户界面中直接显示。这些日志默认存储于各个工作节点的 Spark 目录下的 `work/` 目录。
- 在 Mesos 模式下，日志存储在 Mesos *从节点*的` work/` 目录中，可以通过 Mesos 主节点用户界面访问。
- 在 YARN 模式下，最简单的收集日志的方法是使用 YARN 的日志收集工具（运行 `yarn logs -applicationId <app ID>` ）来生成一个包含应用日志的报告。

Spark 的日志系统是基于广泛使用的 Java 日志库 log4j 实现的，使用 log4j 的配置方式进行配置。log4j 配置的示例文件已经打包在 Spark 中，具体位置是 `conf/log4j.properties.template`。要想自定义 Spark 的日志，首先需要把这个示例文件复制为 `log4j.properties`，然后就可以修改日志行为了。


# 8.4 关键性能考量

## 8.4.1 并行度

在物理执行期间，RDD 会被分为一系列的分区，每个分区都是整个数据的子集。当 Spark 调度并运行任务时，Spark 会为每个分区中的数据创建出一个任务。该任务在默认情况下会需要集群中的一个计算核心来执行。Spark 也会针对 RDD 直接自动推断出合适的并行度，这对于大多数用例来说已经足够了。输入 RDD 一般会根据其底层的存储系统选择并行度。例如，从 HDFS 上读数据的输入 RDD 会为数据在 HDFS 上的每个文件区块创建一个分区。从数据混洗后的 RDD 派生下来的 RDD 则会采用与其父 RDD 相同的并行度。

并行度会从两方面影响程序的性能。

1. 当并行度过低时，Spark 集群会出现资源闲置的情况。
2. 当并行度过高时，每个分区产生的间接开销累计起来就会更大。

评判并行度是否过高的标准包括任务是否是几乎在瞬间（毫秒级）完成的，或者是否观察到任务没有读写任何数据。

Spark 提供了两种方法来对操作的并行度进行调优:

1. 在数据混洗操作时，使用参数的方式为混洗后的 RDD 指定并行度。
2. 对于任何已有的 RDD，可以进行重新分区来获取更多或者更少的分区数。重新分区操作通过 repartition() 实现，该操作会把 RDD 随机打乱并分成设定的分区数目。如果你确定要减少 RDD 分区，可以使用 coalesce() 操作。由于没有打乱数据，该操作比 repartition() 更为高效。如果你认为当前的并行度过高或者过低，可以利用这些方法对数据分布进行重新调整。

## 8.4.2 序列化格式

当 Spark 需要通过网络传输数据，或是将数据溢写到磁盘上时，Spark 需要把数据序列化为二进制格式。序列化会在数据进行混洗操作时发生，此时有可能需要通过网络传输大量数据。默认情况下，Spark 会使用 Java 内建的序列化库。Spark 也支持使用第三方序列化库 Kryo。

```scala
val conf = new SparkConf()
conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
// 严格要求注册类
conf.set("spark.kryo.registrationRequired", "true")
conf.registerKryoClasses(Array(classOf[MyClass], classOf[MyOtherClass]))
```

不论是选用 Kryo 还是 Java 序列化，如果代码中引用到了一个没有扩展 Java 的 `Serializable` 接口的类，你都会遇到 `NotSerializableException` 。很多 JVM 都支持通过一个特别的选项来帮助调试这一情况：`-Dsun.io.serialization.extended DebugInfo=true`。你可以通过设置 `spark-submit` 的 `--driver-java-options` 和 `--executor-java-options` 标记来打开这个选项。一旦找到了有问题的类，最简单的解决方法就是把这个类改为实现了 Serializable 接口的形式。

## 8.4.3 内存管理

在各个执行器进程中，内存有以下用途：

- RDD存储

    当调用 RDD 的 `persist()` 或 `cache()` 方法时，这个 RDD 的分区会被存储到缓存区中。Spark 会根据 `spark.storage.memoryFraction` 限制用来缓存的内存占整个 JVM 堆空间的比例大小。如果超出限制，旧的分区数据会被移出内存。

- 数据混洗与聚合的缓存区

    当进行数据混洗操作时，Spark 会创建出一些中间缓存区来存储数据混洗的输出数据。这些缓存区用来存储聚合操作的中间结果，以及数据混洗操作中直接输出的部分缓存数据。Spark 会尝试根据 `spark.shuffle.memoryFraction` 限定这种缓存区内存占总内存的比例。

- 用户代码

    Spark 可以执行任意的用户代码，所以用户的函数可以自行申请大量内存。用户代码可以访问 JVM 堆空间中除分配给 RDD 存储和数据混洗存储以外的全部剩余空间。

在默认情况下，Spark 会使用 60％的空间来存储 RDD，20% 存储数据混洗操作产生的数据，剩下的 20% 留给用户程序。用户可以自行调节这些选项来追求更好的性能表现。


Spark 默认的 `cache()` 操作会以 `MEMORY_ONLY` 的存储等级持久化数据。这意味着如果缓存新的 nRDD 分区时空间不够，旧的分区就会直接被删除。当用到这些分区数据时，再进行重算。所以有时以 `MEMORY_AND_DISK` 的存储等级调用 `persist()` 方法会获得更好的效果，因为在这种存储等级下，内存中放不下的旧分区会被写入磁盘，当再次需要用到的时候再从磁盘上读取回来。

对于默认缓存策略的另一个改进是**缓存序列化后的对象**而非直接缓存。我们可以通过 `MEMORY_ONLY_SER` 或者 `MEMORY_AND_DISK_SER` 的存储等级来实现这一点。缓存序列化后的对象会使缓存过程变慢，因为序列化对象也会消耗一些代价，不过这可以显著减少 JVM 的垃圾回收时间，因为很多独立的记录现在可以作为单个序列化的缓存而存储。垃圾回收的代价与堆里的对象数目相关，而不是和数据的字节数相关。这种缓存方式会把大量对象序列化为一个巨大的缓存区对象。如果你需要以对象的形式缓存大量数据（比如数 GB 的数据），或者是注意到了长时间的垃圾回收暂停，可以考虑配置这个选项。

## 8.4.4 硬件供给

提供给 Spark 的硬件资源会显著影响应用的完成时间。影响集群规模的主要参数包括分配给每个执行器节点的内存大小、每个执行器节点占用的核心数、执行器节点总数，以及用来存储临时数据的本地磁盘数量。

更大的内存和更多的计算核心对 Spark 应用会更有用处。Spark 的架构允许线性伸缩；双倍的资源通常能使应用的运行时间减半。除了内存和 CPU 核心，Spark 还要用到本地磁盘来存储数据混洗操作的中间数据，以及溢写到磁盘中的 RDD 分区数据。因此，使用大量的本地磁盘可以帮助提升 Spark 应用的性能。

切记，“越多越好”的原则在设置执行器节点内存时并不一定适用。使用巨大的堆空间可能会导致垃圾回收的长时间暂停，从而严重影响 Spark 作业的吞吐量。



# 导航

[目录](README.md)

上一章：[7. 在集群上运行Spark](7. 在集群上运行Spark.md)

下一章：[9. Spark SQL](9. Spark SQL.md)
