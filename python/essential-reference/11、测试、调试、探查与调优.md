<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [11.1 Documentation Strings and the `doctest` Module](#111-documentation-strings-and-the-doctest-module)
- [11.2 Unit Testing and the `unittest` Module](#112-unit-testing-and-the-unittest-module)
- [11.3 The Python Debugger and the `pdb` Module](#113-the-python-debugger-and-the-pdb-module)
  - [Debugger Commands](#debugger-commands)
  - [Debugging from the Command Line](#debugging-from-the-command-line)
  - [Configuring the Debugger](#configuring-the-debugger)
- [11.4 Program Profiling](#114-program-profiling)
- [11.5 Tuning and Optimization](#115-tuning-and-optimization)
  - [Making Timing Measurements](#making-timing-measurements)
  - [Making Memory Measurements](#making-memory-measurements)
  - [Disassembly](#disassembly)
  - [Tuning Strategies](#tuning-strategies)
- [Navigation](#navigation)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

In Python, you will never really know if your program is correct until you run and test it. Not only that, unless you are able to run your program in a way that executes every possible branch of its internal control-flow, there is always some chance of a hidden error just waiting to strike.

# 11.1 Documentation Strings and the `doctest` Module

If the first line of a function, class, or module is a string, that string is known as a documentation string. The `help()` command inspects documentation strings, and Python IDEs look at the strings as well.

```python
# splitter.py
def split(line, types=None, delimiter=None):
    """Splits a line of text and optionally performs type conversion.
        For example:
        >>> split('GOOG 100 490.50')
        ['GOOG', '100', '490.50']
        >>> split('GOOG 100 490.50',[str, int, float])
        ['GOOG', 100, 490.5]
        >>>
        By default, splitting is performed on whitespace, but a different
        delimiter can be selected with the delimiter keyword argument:
        >>> split('GOOG,100,490.50',delimiter=',')
        ['GOOG', '100', '490.50']
        >>>
    """
    fields = line.split(delimiter)
    if types:
        fields = [ ty(val) for ty,val in zip(types,fields) ]
    return fields
```

A common problem with writing documentation is keeping the documentation synchronized with the actual implementation of a function. To address this problem, use the `doctest` module. `doctest` collects documentation strings, scans them for interactive sessions, and executes them as a series of tests. To use doctest, you typically create a separate module for testing. For example, if the previous function is in a file `splitter.py`, you would create a file `testsplitter.py` for testing, as follows:

```python
# testsplitter.py
import splitter
import doctest
nfail, ntests = doctest.testmod(splitter)
```

`doctest` expects the output of functions to literally match the exact output you get in the interactive interpreter.

```python
def half(x):
    """Halves x. For example:
    >>> half(6.8)
    3.4
    >>>
    """
    return x/2
```

If you run `doctest` on this function, you will get a failure report such as this:

```
**********************************************************************
File "half.py", line 4, in _ _main_ _.half
Failed example:
    half(6.8)
Expected:
    3.4
Got:
    3.3999999999999999
**********************************************************************
```


# 11.2 Unit Testing and the `unittest` Module

With unit testing, a developer writes a collection of isolated test cases for each element that makes up a program.

```python
# splitter.py
def split(line, types=None, delimiter=None):
    """Splits a line of text and optionally performs type conversion.
    ...
    """
    fields = line.split(delimiter)
    if types:
        fields = [ ty(val) for ty,val in zip(types,fields) ]
    return fields
```

```python
# testsplitter.py
import splitter
import unittest

# Unit tests
class TestSplitFunction(unittest.TestCase):
    def setUp(self):
        # Perform set up actions (if any)
        pass
    def tearDown(self):
        # Perform clean-up actions (if any)
        pass
    def testsimplestring(self):
        r = splitter.split('GOOG 100 490.50')
        self.assertEqual(r,['GOOG','100','490.50'])
    def testtypeconvert(self):
        r = splitter.split('GOOG 100 490.50',[str, int, float])
        self.assertEqual(r,['GOOG', 100, 490.5])
    def testdelimiter(self):
        r = splitter.split('GOOG,100,490.50',delimiter=',')
        self.assertEqual(r,['GOOG','100','490.50'])

# Run the unittests
if _ _name_ _ == '_ _main_ _':
    unittest.main()
```

To run tests, simply run Python on the file `testsplitter.py`. Here’s an example:

```
% python testsplitter.py
...
----------------------------------------------------------------------
Ran 3 tests in 0.014s
OK
```

Basic use of unittest involves defining a class that inherits from `unittest.TestCase`. Within this class, individual tests are defined by methods starting with the name 'test'.

An instance, `t`, of `unittest.TestCase` has the following methods that are used when writing tests and for controlling the testing process:

`t.setUp()`
Called to perform set-up steps prior to running any of the testing methods. |

`t.tearDown()`
Called to perform clean-up actions after running the tests. |

`t.assert_(expr [, msg])`
`t.failUnless(expr [, msg])`
Signals a test failure if expr evaluates as False. msg is a message string giving an explanation for the failure (if any).

`t.assertEqual(x, y [,msg])`
`t.failUnlessEqual(x, y [, msg])`
Signals a test failure if x and y are not equal to each other. msg is a message explaining the failure (if any).


# 11.3 The Python Debugger and the `pdb` Module

The `pdb` module supports post-mortem debugging, inspection of stack frames, breakpoints, single-stepping of source lines, and code evaluation.

There are several functions for invoking the debugger from a program or from the interactive Python shell.

```python
# Executes the string statement under debugger control
run(statement [, globals [, locals]])

# Evaluates the expression string under debugger control
runeval(expression [, globals [, locals]])

# Call a function within the debugger
runcall(function [, argument, ...])

# Starts the debugger at the point at which this function is called.
set_trace()

# Starts post-mortem debugging of a traceback object
post_mortem(trackback)

# Enters post-motrtem debugging using the traceback of the last exception
pm()
```

## Debugger Commands

When the debugger starts, it presents a (Pdb) prompt such as the following:

```
>>> import pdb
>>> import buggymodule
>>> pdb.run('buggymodule.start()')
> <string>(0)?()
(Pdb)
```

(Pdb) is the debugger prompt at which the following commands are recognized.

| command                           | description                              |
| --------------------------------- | ---------------------------------------- |
| [!]statement                      | Executes the (one-line) statement in the context of the current stack frame |
| a(rgs)                            | Prints the argument list of the current function |
| alias [name [command]]            | Creates an alias called name that executes command |
| b(reak) [loc [, condition]]       | Sets a breakpoint at location loc. loc either specifies a specific filename and line number |
| cl(ear) [bpnumber [bpnumber ...]] | Clears a list of breakpoint numbers      |
| commands [bpnumber]               | Sets a series of debugger commands to execute automatically when the breakpoint |
| condition bpnumber [condition]    | Places a condition on a breakpoint       |
| c(ont(inue))                      | Continues execution until the next breakpoint is encountered. |
| disable [bpnumber [bpnumber ...]] | Disables the set of specified breakpoints |
| d(own)                            | Moves the current frame one level down in the stack trace |
| h(elp) [command]                  | Shows the list of available commands     |
| ignore bpnumber [count]           | Ignores a breakpoint for count executions. |
| j(ump) lineno                     | Sets the next line to execute            |
| l(ist) [first [, last]]           | Lists source code                        |
| n(ext)                            | Executes until the next line of the current function |
| p expression                      | Evaluates the expression in the current context and prints its value |
| pp expression                     | The same as the p command, but the result is formatted using the pretty-printing module |
| q(uit)                            | Quits from the debugger                  |
| r(eturn)                          | Runs until the current function returns  |
| run [args]                        | Restarts the program and uses the command-line arguments in args as the new setting |
| s(tep)                            | Executes a single source line and stops inside called functions |
| tbreak [loc [, condition]]        | Sets a temporary breakpoint that’s removed after its first hit |
| u(p)                              | Moves the current frame one level up in the stack trace |
| unalias name                      | Deletes the specified alias              |
| until                             | Resumes execution until control leaves the current execution frame or until a line |
| w(here)                           | Prints a stack trace                     |

## Debugging from the Command Line

Alternative method for running the debugger is to invoke it on the command line:

```shell
python -m pdb someprogram.py
```

## Configuring the Debugger

If a `.pdbrc` file exists in the user’s home directory or in the current directory, it’s read in and executed as if it had been typed at the debugger prompt.


# 11.4 Program Profiling

The `profile` and `cProfile` modules are used to collect profiling information. `cProfile` is implemented as a C extension, is significantly faster, and is more modern. Either module is used to collect both coverage information (that is, what functions get executed) as well as performance statistics.

The easiest way to profile a program is to execute it from the command line as follows:

```shell
python -m cProfile someprogram.py
```

Alternatively, the following function in the profile module can be used:

```python
run(command [, filename])
```

Different parts of the report generated by run() are interpreted as follows:

| Section                   | Description                              |
| ------------------------- | ---------------------------------------- |
| primitive calls           | Number of nonrecursive function calls    |
| ncalls                    | Total number of calls (including self-recursion) |
| tottime                   | Time spent in this function (not counting subfunctions) |
| percall                   | tottime/ncalls                           |
| cumtime                   | Total time spent in the function         |
| percall                   | cumtime/(primitive calls)                |
| filename:lineno(function) | Location and name of each function       |


# 11.5 Tuning and Optimization

## Making Timing Measurements

If you simply want to time a long-running Python program, the easiest way to do it is often just to run it until the control of something like the UNIX time command.
```python
start_cpu = time.clock()
start_real= time.time()
statements
statements
end_cpu = time.clock()
end_real = time.time()
print("%f Real Seconds" % (end_real – start_real))
print("%f CPU seconds" % (end_cpu - start_cpu))
```

If you have a fine-grained statement you want to benchmark, you can use the `timeit(code [, setup])` function in the timeit module.

```python
from timeit import timeit
timeit('math.sqrt(2.0)','import math')
timeit('sqrt(2.0)','from math import sqrt')
```

The `timeit()` function runs the supplied statement one million times and reports the execution time.The number of repetitions can be changed by supplying a `number=count` keyword argument to `timeit()`.

The timeit module also has a function `repeat()` that can be used to make measurements. This function repeats the timing measurement three times and returns a list of the results.

## Making Memory Measurements

The sys module has a function `getsizeof()` that can be used to investigate the memory footprint (in bytes) of individual Python objects.

```python
import sys
sys.getsizeof(1) # 14
sys.getSizeof('Hello World') # 52
sys.getsizeof([1,2,3,4]) # 52
sum(sys.getsizeof(x) for x in [1,2,3,4]) # 56
```

For containers such as lists, tuples, and dictionaries, the size that gets reported is just for the container object itself, not the cumulative size of all objects contained inside of it.

Internally, the interpreter aggressively shares objects via reference counting so the actual memory consumed by an object might be far less than you first imagine. Also, given that C extensions to Python can allocate memory outside of the interpreter, it may be difficult to precisely get a measurement of overall memory use. Thus, a secondary technique for measuring the actual memory footprint is to inspect your running program from an operating system process viewer or task manager.

## Disassembly

The `dis` module can be used to disassemble Python functions, methods, and classes into low-level interpreter instructions.The module defines a function `dis()` that can be used like this:

```python
from dis import dis
dis(split)
```

A disassembly will show you exactly what operations are involved in executing a function. Second, if you are programming with threads, each line printed in the disassembly represents a single interpreter operation—each of which has atomic execution.Thus, if you are trying to track down a tricky race condition, this information might be useful.

## Tuning Strategies

**1. Understand your program**

Before you optimize anything, know that speedup obtained by optimizing part of a program is directly related to that part’s total contribution to the execution time.

It is always a good idea to first use the profiling module on code you intend to optimize. You really only want to focus on functions and methods where your program spends most of its time, not obscure operations that are called only occasionally.

- Understand Algorithms

A poorly implemented O(n log n) algorithm will outperform the most finely tuned O(n3) algorithm.

- Use the Built-In Types

Python’s built-in tuple, list, set, and dictionary types are implemented entirely in C and are the most finely tuned data structures in the interpreter.

Having said that, you should still look more closely at types in the standard library.

**2. Don't Add Layers**

Any time you add an extra layer of abstraction or convenience to an object or a function, you will slow down your program. However, there is also a trade-off between usability and performance.

```
>>> timeit("s = {'name':'GOOG','shares':100,'price':490.10}")
0.38917303085327148
>>> timeit("s = dict(name='GOOG',shares=100,price=490.10)")
0.94420003890991211
```

**3. Know How Classes and Instances Build Upon Dictionaries**

User-defined classes and instances are built using dictionaries. Because of this, operations that look up, set, or delete instance data are almost always going to run more slowly than directly performing these operations on a dictionary.

If all you are doing is building a simple data structure for storing data, a dictionary may be a more efficient choice than defining a class.

```
>>> from timeit import timeit
>>> timeit("s = Stock('GOOG',100,490.10)","from stock import Stock")
1.3166780471801758
>>> timeit("s = {'name' : 'GOOG', 'shares' : 100, 'price' : 490.10 }")
0.37812089920043945
>>>
```

**4. Use `__slots__`**

`__slots__` is sometimes viewed as a safety feature because it restricts the set of attribute names. However, it is really more of a performance optimization.

Classes that use `__slots__` don’t use a dictionary for storing instance data. So, not only will instances use far less memory, but access to instance data is also more efficient.

**5. Avoid the (.) Operator**

Whenever you use the (.) to look up an attribute on an object, it always involves a name lookup. For user-defined objects, attribute lookup may involve looking in the instance dictionary, the class dictionary, and the dictionaries of base-classes.

For calculations involving heavy use of methods or module lookups, it is almost always better to eliminate the attribute lookup by putting the operation you want to perform into a local variable first. For example, if you were performing a lot of square root operations, it is faster to use `from math import sqrt` and `sqrt(x)` rather than typing `math.sqrt(x)`.

**6. Use Exceptions to Handle Uncommon Cases**

```python
def parse_header(line):
    fields = line.split(":")
    if len(fields) != 2:
        raise RuntimeError("Malformed header")
    header, value = fields
    return header.lower(), value.strip()
```

```python
def parse_header(line):
    fields = line.split(":")
    try:
        header, value = fields
        return header.lower(), value.strip() 
    except ValueError:
        raise RuntimeError("Malformed header")
```

The second version of code runs about 10 percent faster. Setting up a `try` block for code that normally doesn’t raise an exceptions runs more quickly than executing an `if` statement.

**7. Avoid Exceptions for Common Cases**

```python
# Approach 1 : Perform a lookup and catch an exception
try:
    value = items[key]
except KeyError:
    value = None
# Approach 2: Check if the key exists and perform a lookup
if key in items:
    value = items[key]
else:
    value = None
```

In a simple performance measurement where the key is not found, the second approach runs more than 17 times faster. This latter approach also runs almost twice as fast as using `items.get(key)` because the `in` operator is faster to execute than a method call.

**8. Embrace Functional Programming and Iteration**

List comprehensions, generator expressions, generators, coroutines, and closures are much more efficient than most Python programmers realize.

**9. Use Decorators and Metaclasses**

Decorators and metaclasses are features that are used to modify functions and classes. However, because they operate at the time of function or class definition, they can be used in ways that lead to improved performance—especially if a program has many optional features that might be turned on or off.


# Navigation

[Table of Contents](README.md)

Prev: [10、执行环境](10、执行环境.md)

Next: [12. Build-In Functions and Exceptions](12-built-in-functions-and-exceptions.md)
