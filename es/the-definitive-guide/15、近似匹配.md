<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [短语匹配](#%E7%9F%AD%E8%AF%AD%E5%8C%B9%E9%85%8D)
  - [词项的位置](#%E8%AF%8D%E9%A1%B9%E7%9A%84%E4%BD%8D%E7%BD%AE)
- [混合起来](#%E6%B7%B7%E5%90%88%E8%B5%B7%E6%9D%A5)
- [多值字段](#%E5%A4%9A%E5%80%BC%E5%AD%97%E6%AE%B5)
- [越近越好](#%E8%B6%8A%E8%BF%91%E8%B6%8A%E5%A5%BD)
- [使用邻近度提高相关度](#%E4%BD%BF%E7%94%A8%E9%82%BB%E8%BF%91%E5%BA%A6%E6%8F%90%E9%AB%98%E7%9B%B8%E5%85%B3%E5%BA%A6)
- [性能优化](#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96)
  - [结果集重新评分](#%E7%BB%93%E6%9E%9C%E9%9B%86%E9%87%8D%E6%96%B0%E8%AF%84%E5%88%86)
- [寻找相关词](#%E5%AF%BB%E6%89%BE%E7%9B%B8%E5%85%B3%E8%AF%8D)
  - [Performance性能](#performance%E6%80%A7%E8%83%BD)
- [导航](#%E5%AF%BC%E8%88%AA)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 短语匹配

想找到彼此邻近搜索词的查询方法时，就会想到 `match_phrase` 查询 。

```
GET /my_index/my_type/_search
{
    "query": {
        "match_phrase": {
            "title": "quick brown fox"
        }
    }
}
```

`match_phrase` 查询首先将查询字符串解析成一个词项列表，然后对这些词项进行搜索，但只保留那些包含 *全部* 搜索词项，且 *位置* 与搜索词项相同的文档。

## 词项的位置

当一个字符串被分词后，这个分析器不但会 返回一个词项列表，而且还会返回各词项在原始字符串中的 *位置* 或者顺序关系：

```
GET /_analyze?analyzer=standard
Quick brown fox
```

返回信息如下：

```
{
   "tokens": [
      {
         "token": "quick",
         "start_offset": 0,
         "end_offset": 5,
         "type": "<ALPHANUM>",
         "position": 1 
      },
      {
         "token": "brown",
         "start_offset": 6,
         "end_offset": 11,
         "type": "<ALPHANUM>",
         "position": 2 
      },
      {
         "token": "fox",
         "start_offset": 12,
         "end_offset": 15,
         "type": "<ALPHANUM>",
         "position": 3 
      }
   ]
}
```

一个被认定为和短语 `quick brown fox` 匹配的文档，必须满足以下这些要求：

- `quick` 、 `brown` 和 `fox` 需要全部出现在域中。
- `brown` 的位置应该比 `quick` 的位置大 `1` 。
- `fox` 的位置应该比 `quick` 的位置大 `2` 。

如果以上任何一个选项不成立，则该文档不能认定为匹配。

# 混合起来

精确短语匹配 或许是过于严格了。也许我们想要包含 “quick brown fox” 的文档也能够匹配 “quick fox,” ， 尽管情形不完全相同。

我们能够通过使用 `slop` 参数将灵活度引入短语匹配中：

```
GET /my_index/my_type/_search
{
    "query": {
        "match_phrase": {
            "title": {
                "query": "quick fox",
                "slop":  1
            }
        }
    }
}
```

`slop` 参数告诉 `match_phrase` 查询词条相隔多远时仍然能将文档视为匹配 。 相隔多远的意思是为了让查询和文档匹配你需要移动词条多少次？有了足够大的 `slop` 值， 单词就能按照任意顺序排列了。



# 多值字段

```
PUT /my_index/groups/1
{
    "names": [ "John Abraham", "Lincoln Smith"]
}
```

然后运行一个对 `Abraham Lincoln` 的短语查询:

```
GET /my_index/groups/_search
{
    "query": {
        "match_phrase": {
            "names": "Abraham Lincoln"
        }
    }
}
```

令人惊讶的是， 即使 `Abraham` 和 `Lincoln` 在 `names` 数组里属于两个不同的人名， 我们的文档也匹配了查询。 这一切的原因在Elasticsearch数组的索引方式。

幸运的是， 在这样的情况下有一种叫做 `position_increment_gap` 的简单的解决方案， 它在字段映射中配置 。

```
DELETE /my_index/groups/ 

PUT /my_index/_mapping/groups 
{
    "properties": {
        "names": {
            "type":                "string",
            "position_increment_gap": 100
        }
    }
}
```

`position_increment_gap` 设置告诉 Elasticsearch 应该为数组中每个新元素增加当前词条 `position` 的指定值。 所以现在当我们再索引 names 数组时，会产生如下的结果：

- Position 1: `john`
- Position 2: `abraham`
- Position 103: `lincoln`
- Position 104: `smith`

现在我们的短语查询可能无法匹配该文档因为 `abraham` 和 `lincoln` 之间的距离为 100 。



# 越近越好

鉴于一个短语查询仅仅排除了不包含确切查询短语的文档， 而 *邻近查询* — 一个 `slop` 大于 `0`— 的短语查询将查询词条的邻近度考虑到最终相关度 `_score` 中。 通过设置一个像 `50` 或者 `100` 这样的高 `slop` 值, 你能够排除单词距离太远的文档， 但是也给予了那些单词临近的的文档更高的分数。

```
POST /my_index/my_type/_search
{
   "query": {
      "match_phrase": {
         "title": {
            "query": "quick dog",
            "slop":  50 
         }
      }
   }
}
```



# 使用邻近度提高相关度

 如果七个词条中有六个匹配， 那么这个文档对用户而言就已经足够相关了， 但是 `match_phrase` 查询可能会将它排除在外。

可以将一个简单的 `match` 查询作为一个 `must` 子句。 这个查询将决定哪些文档需要被包含到结果集中。 我们可以用 `minimum_should_match` 参数去除长尾。 然后我们可以以 `should` 子句的形式添加更多特定查询。 每一个匹配成功的都会增加匹配文档的相关度。

```
GET /my_index/my_type/_search
{
  "query": {
    "bool": {
      "must": {
        "match": { 
          "title": {
            "query":                "quick brown fox",
            "minimum_should_match": "30%"
          }
        }
      },
      "should": {
        "match_phrase": { 
          "title": {
            "query": "quick brown fox",
            "slop":  50
          }
        }
      }
    }
  }
}
```



# 性能优化

短语查询和邻近查询都比简单的 `query` 查询代价更高 。 一个 `match` 查询仅仅是看词条是否存在于倒排索引中，而一个 `match_phrase` 查询是必须计算并比较多个可能重复词项的位置。

介绍性能消耗，一种有用的方法是减少需要通过短语查询检查的文档总数。

## 结果集重新评分

`search` API 通过 *重新评分* 明确支持该功能。重新评分阶段支持一个代价更高的评分算法--比如 `phrase`查询--只是为了从每个分片中获得前 `K` 个结果。 然后会根据它们的最新评分 重新排序。

该请求如下所示：

```
GET /my_index/my_type/_search
{
    "query": {
        "match": {  
            "title": {
                "query":                "quick brown fox",
                "minimum_should_match": "30%"
            }
        }
    },
    "rescore": {
        "window_size": 50, 
        "query": {         
            "rescore_query": {
                "match_phrase": {
                    "title": {
                        "query": "quick brown fox",
                        "slop":  50
                    }
                }
            }
        }
    }
}
```



# 寻找相关词

短语查询和邻近查询都很好用，但仍有一个缺点。它们过于严格了：为了匹配短语查询，所有词项都必须存在，即使使用了 `slop` 。

如果索引单词对而不是索引独立的单词，就能对这些单词的上下文尽可能多的保留。

对句子 `Sue ate the alligator` ，不仅要将每一个单词（或者 *unigram* ）作为词项索引

```
["sue", "ate", "the", "alligator"]
```

也要将每个单词 *以及它的邻近词* 作为单个词项索引：

```
["sue ate", "ate the", "the alligator"]
```

这些单词对（或者 *bigrams* ）被称为 *shingles* 。

当然，只有当用户输入的查询内容和在原始文档中顺序相同时，shingles 才是有用的；对 `sue alligator`的查询可能会匹配到单个单词，但是不会匹配任何 shingles 。

Shingles 需要在索引时作为分析过程的一部分被创建。 我们可以将 unigrams 和 bigrams 都索引到单个字段中， 但将它们分开保存在能被独立查询的字段会更清晰。unigrams 字段将构成我们搜索的基础部分，而 bigrams 字段用来提高相关度。

首先，我们需要在创建分析器时使用 `shingle` 语汇单元过滤器：

```
DELETE /my_index

PUT /my_index
{
    "settings": {
        "number_of_shards": 1,  
        "analysis": {
            "filter": {
                "my_shingle_filter": {
                    "type":             "shingle",
                    "min_shingle_size": 2, 
                    "max_shingle_size": 2, 
                    "output_unigrams":  false   
                }
            },
            "analyzer": {
                "my_shingle_analyzer": {
                    "type":             "custom",
                    "tokenizer":        "standard",
                    "filter": [
                        "lowercase",
                        "my_shingle_filter" 
                    ]
                }
            }
        }
    }
}
```

为了理解添加 `shingles` 字段的好处 ，让我们首先来看 `The hungry alligator ate Sue` 进行简单 `match` 查询的结果：

```
GET /my_index/my_type/_search
{
   "query": {
        "match": {
           "title": "the hungry alligator ate sue"
        }
   }
}
```

## Performance性能

shingles 不仅比短语查询更灵活， 而且性能也更好。 shingles 查询跟一个简单的 `match` 查询一样高效，而不用每次搜索花费短语查询的代价。只是在索引期间因为更多词项需要被索引会付出一些小的代价， 这也意味着有 shingles 的字段会占用更多的磁盘空间。 然而，大多数应用写入一次而读取多次，所以在索引期间优化我们的查询速度是有意义的。

这是一个在 Elasticsearch 里会经常碰到的话题：不需要任何前期进行过多的设置，就能够在搜索的时候有很好的效果。 一旦更清晰的理解了自己的需求，就能在索引时通过正确的为你的数据建模获得更好结果和性能。



# 导航

[目录](README.md)

上一章：[14、多字段搜索](14、多字段搜索.md)

下一章：[16、部分匹配](16、部分匹配.md)
